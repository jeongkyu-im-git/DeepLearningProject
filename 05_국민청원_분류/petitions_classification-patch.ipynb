{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 국민청원 분류하기 패치 Notebook\n",
    "\n",
    "본 Notebook 파일은 기존 Notebook 파일을 실행 할 수 없는 상황을 해결한 패치 Notebook 입니다.\n",
    "\n",
    "## 주의사항\n",
    "1. 새로운 가상환경을 만들어서 실행하세요. 기존 환경에서 진행 시 버전 문제로 오류 발생 할 수 있습니다.\n",
    "2. 기존 환경에서 실행 할 경우 아래 uninstall 명령을 통해 모든 모듈을 삭제하세요.\n",
    "3. 모듈 설치는 install 명령으로 모듈 설치하세요.\n",
    "4. konlpy 모듈에서 JAVA 모듈을 요구할 수 있습니다.\n",
    " - 버전 호환성 문제로 여기서는 1.8.x 버전을 설치했습니다.\n",
    " - mac os : zulu-1.8.x 버전 설치 후 테스트 완료.\n",
    " - windows : 테스트 후 버전 확인 예정 \n",
    "\n",
    "## Install Dependencies\n",
    "\n",
    "```\n",
    "# uninstall \n",
    "pip freeze > installed-requirements.txt\n",
    "pip uninstall -r installed-requirements.txt -y\n",
    "\n",
    "# install\n",
    "pip install -r requirements-patch.txt\n",
    "```\n",
    "\n",
    "## 준비 사항\n",
    "\n",
    "crawling.zip 압축 해제 : crawling.csv 파일은 data 폴더 아래로 이동(Move) 시켜 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "국민 청원 사이트가 없어진 관계로 크롤링 영역은 삭제했습니다.\n",
    "\n",
    "크롤링 코드는 원본 Notebook 에서 확인하세요.\n",
    "\n",
    "크롤링 데이터는 `data/crawling.csv` 로 제공됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 csv 파일 읽기\n",
    "df = pd.read_csv('data/crawling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다. 하지만 투자매력이 없다고도 합니다.이렇게 말하는 이유가 어디 있습니까? 바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다.\\r\\n\\r\\r\\n지금은 투자매력이 없어서 그렇지,..우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과, 외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다. 그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다.\\r\\n\\r\\r\\n정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데,... 그렇지 못한 현실이 안타깝다고 생각합니다.\\r\\r\\n국가가 지원해 돈 들이기가 어려우면,정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다. \\r\\n\\r\\r\\n그래서 저는 정부에 다음과 같이 청원합니다.\\r\\r\\n주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서,...\\r\\n\\r\\r\\n첫째,주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오 \\r\\n\\r\\r\\n둘째,  코스닥 종목은 공매도 제외시켜 주세요.\\r\\n\\r\\r\\n공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다 \\r\\n\\r\\r\\n셋째, 거래시장의 주식거래세를 더 낮춰 주세요 \\r\\n\\r\\r\\n특히 개미(소액)투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다.\\r\\n\\r\\r\\n넷째, 중,장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요.\\r\\n\\r\\r\\n이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']  # 전처리 전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[전처리]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다  하지만 투자매력이 없다고도 합니다 이렇게 말하는 이유가 어디 있습니까  바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다      지금은 투자매력이 없어서 그렇지 우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과  외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다  그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다      정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데  그렇지 못한 현실이 안타깝다고 생각합니다    국가가 지원해 돈 들이기가 어려우면 정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다       그래서 저는 정부에 다음과 같이 청원합니다    주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서      첫째 주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오      둘째   코스닥 종목은 공매도 제외시켜 주세요      공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다      셋째  거래시장의 주식거래세를 더 낮춰 주세요      특히 개미 소액 투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다      넷째  중 장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요      이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다 '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']  # 전처리 후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 토크나이징 및 변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[토크나이징]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK 64-Bit Server VM warning: Attempt to protect stack guard pages failed.\n",
      "OpenJDK 64-Bit Server VM warning: Attempt to deallocate stack guard pages failed.\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import platform\n",
    "\n",
    "# check platform\n",
    "platform_name = platform.system()\n",
    "print(f'Platform name : {platform_name}')\n",
    "\n",
    "if platform_name=='Darwin': # for mac os\n",
    "    # mac os 에서 실행 시 JVM 오류로 발생\n",
    "    # JVM 1.8 버전 요구\n",
    "    # JDK 설치 후 설치된 폴더명 변경 : jdk-1.8.jdk -> jdk-1.8.0.jdk\n",
    "    # JVM_PATH konlpy 가 요구하는 dylib 파일 경로로 셋팅.\n",
    "    # JVM_PATH 경로는 개인 환경에 맞게 수정 적용\n",
    "    JVM_PATH = '/Library/Java/JavaVirtualMachines/zulu-1.8.0.jdk/Contents/Home/jre/lib/jli/libjli.dylib'\n",
    "    okt = Okt(jvmpath=JVM_PATH)\n",
    "else:\n",
    "    okt = Okt()\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "df['content_token'] = df.content.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[파생변수 생성]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category         object\n",
      "content          object\n",
      "count             int64\n",
      "end              object\n",
      "start            object\n",
      "title            object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_drop = df[['token_final', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final label\n",
       "0  [서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...    No\n",
       "1  [주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...    No\n",
       "2  [교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...    No\n",
       "3  [미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...    No\n",
       "4  [악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...   Yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 엑셀로 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 단어 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[단어 임베딩]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=42642, vector_size=100, alpha=0.025>\n",
      "[('음주', 0.8759000897407532), ('무면허', 0.8348441123962402), ('뺑소니', 0.817329466342926), ('살인자', 0.7560948729515076), ('윤창', 0.751399040222168), ('형량', 0.7436730265617371), ('승자', 0.7400760054588318), ('전과자', 0.738017201423645), ('운전자', 0.737915575504303), ('살인죄', 0.7365405559539795)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'], \n",
    "                           sg = 1, # skip-gram\n",
    "                           vector_size = 100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 4\n",
    "                           )\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[임베딩 모델 저장 및 로드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('음주', 0.8759000897407532), ('무면허', 0.8348441123962402), ('뺑소니', 0.817329466342926), ('살인자', 0.7560948729515076), ('윤창', 0.751399040222168), ('형량', 0.7436730265617371), ('승자', 0.7400760054588318), ('전과자', 0.738017201423645), ('운전자', 0.737915575504303), ('살인죄', 0.7365405559539795)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v') # 모델 로드\n",
    "\n",
    "model_result = loaded_model.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 실험 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터셋 분할 및 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Field클래스 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['현', '정부', '국토부', '의', '부동산대책', '방향성', '에', '의', '구심', '이', '듭니', '다', '현', '정부', '국토부', '의', '부동산대책', '방향성', '의', '구심', '듭니', '지금', '주택', '가격', '안정화', '가장', '절실', '시기', '지난', '여', '차례', '부동산', '대책', '슬로건', '항상', '집값', '안정', '실상', '그', '내용', '집값', '안정', '오히려', '집값', '정도', '의도', '생각', '듭니', '분명', '행정부', '매우', '인재', '차고', '텐데', '지금', '대책', '그', '의도', '매우', '혹시', '이전', '정권', '가계부채', '시한', '폭탄', '때문', '집값', '안정', '포기', '다음', '정권', '그', '폭탄', '의도', '의심', '심정', '혹', '의도', '진심', '주택', '가격', '전월세', '대란', '금', '현실', '바로', '잡고', '이', '글', '꼭', '참고', '시기', '택시', '안정은', '단지', '무', '주택', '자', '어려움', '문제', '앞', '국가', '경제', '근본', '중차', '문제', '따라서', '현재', '징벌', '조세', '정책', '성적', '합리', '판단', '현', '택시', '필요', '자본주의', '체제', '주택', '시장', '원리', '가격', '거래량', '결정', '하나', '재화', '또한', '국민', '삶', '기본권', '연관', '그', '관련', '정책', '때', '장기', '플랜', '가지', '현', '정부', '전혀', '핀셋', '정책', '무수', '오히려', '택시', '더욱', '혼탁', '국민', '정부', '대한', '실망', '상황', '이', '저', '아래', '몇', '가지', '정책', '제안', '그로', '예상', '효과', '대하', '몇', '자', '앞', '주택', '정책', '방향', '하향', '안정화', '방향', '정책', '현재', '정부', '여러', '정책', '결과', '집값', '거래량', '위축', '주택', '시장', '자체', '마치', '칼날', '위', '듯', '위태', '상황', '사실', '더', '걱정', '집값', '더', '문제', '상황', '외부', '충격', '가해', '지게', '집값', '폭락', '가계부채', '부도', '연쇄', '미노', '현상', '염려', '과거', '나', '미국', '써브', '프라임', '모기지', '사태', '재현', '우려', '나라', '전체', '혼란', '수도', '때문', '따라서', '택시', '안정화', '위해', '가장', '불', '하향', '안정화', '로', '거래량', '착륙', '시도', '주택', '가격', '안정', '위', '경제학', '관점', '볼', '때', '공급', '곡선', '우측', '동시', '즉', '급량', '증대', '공급', '증가', '가격', '안정', '거래량', '수', '주택', '공급', '두', '가지', '요소', '첫', '번', '신규', '주택', '건설', '두', '번', '기존', '주택', '소유자', '시장', '공급', '것', '신규', '주택', '건설', '현', '정부', '노력', '것', '압니', '다만', '과거', '노태우', '정부', '시절', '건설', '이벤트', '것', '제', '오늘', '제안', '것', '두', '번', '기존', '주택', '소유자', '공급', '증대', '주택', '주택', '공급', '현재', '불', '우리나라', '주택', '보급', '률', '국토교통부', '발표', '자료', '를', '실제', '요', '통계청', '자료', '무', '주택', '가구', '수', '약', '이중', '수도권', '약', '가구', '다시', '말', '주택', '주택', '초과', '보유', '수가', '채', '가량', '것', '지금', '당장', '신규', '건설', '일단', '주택', '자', '잉여', '주택', '시장', '시장', '영향', '것', '주택', '가격', '안정화', '및', '거래', '량', '증가', '역할', '수', '음', '정부', '지금', '시책', '주택', '시장', '수', '마치', '이솝우화', '해님', '구름', '이야기', '구름', '비바람', '지금', '채찍', '당근', '동시', '시점', '정부', '작년', '위주', '사용', '올해', '채찍', '사용', '계속', '실례', '부동산대책', '소득', '세법', '시행', '령', '제', '등', '관련', '법령', '개정', '이상', '장기', '보유', '주택', '도시', '한시', '도세', '중과', '배제', '당근', '제시', '결과', '효과', '오히려', '택시', '더욱', '가열', '제대로', '채찍', '때문', '또한', '현재', '도세', '종부세', '인상', '등', '대책', '이역', '시도', '효과', '주택', '자', '출구', '전략', '때문', '따라서', '저', '기존', '주택', '주택', '급증', '위', '다음', '제시', '도세', '중과세', '영구', '폐지', '한시', '폐지', '현재', '주택', '자', '집값', '팔고', '중과', '세율', '때문', '시장', '못', '이', '제', '자', '입장', '소득', '징벌', '과세', '중과세', '생각', '수도', '세금', '기존', '세법', '정', '누진세', '율과', '양도', '차익', '대한', '중과', '세율', '이내', '이내', '적용', '생각', '이', '시장', '수', '환경', '즉', '출구', '전략', '주어', '보', '유세', '재산세', '종합', '부동산', '세', '를', '대폭', '인상', '현', '정부', '종부세', '율', '나름', '인상', '턱', '개정', '내용', '실질', '대다수', '주택', '적용', '종부세', '율', '해당', '것', '예', '시가', '주택', '세', '채', '가지', '주택', '자의', '종부세', '계산', '공시가격', '현실', '율', '가정', '공정', '시장', '가액', '비율', '적용', '종부세', '원', '집', '채', '이상만', '거', '심리', '전혀', '시장', '이유', '즉', '집값', '이상만', '거', '기대', '시장', '이유', '것', '따라서', '주택', '보유', '미래', '집값', '상승', '수익', '더', '시장', '수', '명분', '제안', '주택', '및', '일시', '주택', '세법', '정', '일정', '규모', '이하', '지방', '주택', '상속', '주택', '등', '대해', '기존', '보', '유세', '재산세', '만', '적용', '주택', '최소', '의', '이상', '세율', '주택', '이상', '소유자', '그', '더', '세율', '현재', '법인', '소유', '주택', '대하', '적용', '종부세', '법', '적용', '정부', '의지', '가장', '점', '위', '두', '가지', '방법', '반드시', '동시', '시행', '효과', '징벌', '채찍', '오히려', '국론', '분열', '야기', '그', '고통', '죄', '서민', '더욱', '전가', '것', '대한민국', '자본주의', '체제', '므', '부디', '시장경제', '논리', '고려', '정책', '진행', '시오', '최근', '동안', '개정', '세법', '각', '조항', '개정', '이해', '위해', '공부', '상황', '아마', '핀셋', '규제', '때문', '것', '세법', '납세', '저항', '수', '징세', '비용', '절약', '수', '국민', '에너지', '세법', '공부', '일반', '생업', '쪽', '수', '수', '국민', '화합', '수', '핀셋', '규제', '절대로', '수', '세', '번', '관리', '방향', '주택', '수요', '중', '투기', '수요', '실수', '요', '오히려', '장려', '생각', '위', '두', '가지', '정책', '시장', '주택', '매물', '투기', '수요', '실수', '자가', '흡수', '주택', '재', '분배', '를', '수', '현', '정부', '소득재분배', '를', '실현', '위해', '최저임금', '인상', '등', '여러', '정책', '시점', '장기', '국가', '백년', '지계', '보더', '것', '이', '시점', '주택', '재', '분배', '를', '서서히', '중산층', '증가', '양극화', '완화', '지난', '부동산대책', '주택', '취득', '세율', '개편', '이점', '긍정', '평가', '최소한', '투기', '수요', '근절', '수', '요', '무', '주택', '실수', '요', '억제', '완화', '쪽', '정책', '입안', '시기', '가령', '규제', '실수', '자', '대폭', '완화', '위', '공급', '증대', '정책', '발생', '매물', '무', '주택', '부담', '흡수', '수', '오히려', '장려', '주택', '재', '분배', '를', '실현', '보', '유세', '재산세', '종부세', '과세', '기준', '일', '연', '연', '현행', '보', '유세', '과세', '기준', '일', '매년', '당시', '부동산', '보', '유세', '대한', '고민', '필요', '즉', '현재', '정부', '보', '유세', '관련', '정책', '무수', '그', '효과', '내년', '직전', '고민', '이기', '정책', '효과', '그', '효과', '시간', '다시', '년', '시간', '보', '유세', '개편', '효과', '지속', '기도', '따라서', '제안', '현행', '보', '유세', '과세', '기준', '일', '연', '기별', '연', '분기', '별', '로', '향후', '부동산', '보', '유세', '정책', '효과', '탄력', '지속', '반영', '수', '시장', '환경', '국토해양부', '통계청', '제공', '통계', '자료', '맹신', '지난', '한국', '감정', '제출', '전국', '주택', '가격', '동향', '조사', '수도권', '년', '대비', '주택', '매매', '가격', '상', '승률', '전세', '가격', '상', '승률', '로', '보고', '정부', '관계자', '나름', '정도', '방어', '평가', '내시', '분', '다수', '것', '압니', '수도권', '주요', '아파트', '몇', '개', '샘플링', '한국', '감정', '조사', '자료', '활용', '시세', '및', '국토해양부', '실', '거래', '조회', '대부분', '이상', '상승', '곳', '음', '알', '수', '현실', '통계', '자료', '괴리', '커서', '확인', '결과', '한국', '감정', '통계', '자료', '과거', '전국', '개', '주택', '표본', '현재', '대한민국', '주택', '수', '제', '내부', '관계자', '표본', '주택', '선정', '방법', '및', '지수', '계산', '방법', '등', '대하', '여', '알', '수', '현실', '통계', '자료', '임', '확실', '대통령', '통계', '자료', '통한', '보고서', '맹신', '자칫', '사안', '위', '정책', '택시', '하향', '안정화', '예상', '긍정', '효과', '대해', '말씀', '첫째', '민심', '수', '현', '정부', '지금', '부동산', '정책', '제외', '외교', '안보', '민주화', '방역', '등', '부동산', '정책', '잘못', '현', '정부', '지지', '대부분', '서민', '층', '상처', '외교', '안보', '등', '분야', '일반', '국민', '피부', '기', '주택', '정책', '의식주', '하나', '지지자', '뼈', '저리', '이제', '제대로', '부동산', '정책', '민심', '둘째', '주택', '재', '분배', '양극화', '완화', '수', '무', '주택', '비율', '제로', '사회주의', '것', '대한민국', '무', '주택가', '비율', '현재', '이하', '로만', '수', '정부', '양극화', '완화', '지대', '역할', '것', '저항', '최소', '세수', '증대', '수', '현', '정부', '오명', '과도', '징벌', '과세', '저항', '증대', '못', '주택', '가격', '오히려', '정부', '지로', '세금', '더', '혈안', '정부', '오명', '중과세', '폐지', '보유', '세율', '인상', '주택', '가격', '안정화', '과정', '저항', '줄', '거래', '량', '증가', '세수', '확보', '두', '마리', '토끼', '모두', '잡', '수', '절호', '기회', '넷째', '외부', '충격', '버팀목', '역할', '것', '현재', '부동산', '시장', '마치', '유리', '위', '것', '외부', '충격', '국가', '전체', '시스템', '수', '사상', '누각', '가계부채', '더', '전', '대책', '강', '구해', '만약', '택시', '실수', '자', '중심', '정착', '외부', '충격', '정도', '수', '힘', '생기', '투기', '자', '투자', '등', '상황', '충격', '그', '피해', '고스', '란', '서민', '가장', '것', '유동성', '관리', '국가', '경제', '발전', '수', '택시', '안정', '곧바로', '시중', '포화', '유동성', '관리', '유동성', '관리', '실시', '유동성', '기업', '자영', '업자', '극빈', '층', '단비', '국가', '발전', '이바지', '것', '존경', '대통령', '제', '제시', '위', '정책', '현', '정부', '실현', '정책', '여당', '절대', '과반', '차지', '정부', '지지율', '은', '현', '시점', '겨울', '이사철', '대란', '민심', '동요', '파고', '더욱', '수', '만약', '이', '시기', '향후', '십년', '안', '기회', '다시', '오기', '것', '정책', '소수', '선의', '피해자', '낳을', '수도', '택시', '안정', '주택', '재', '분배', '소득재분배', '의미', '결과', '국민', '모두', '주택', '더', '이상', '투기', '대상', '생각', '훗날', '역사', '반드시', '기억', '줄', '것'] No\n",
      "Validation: ['자산', '운용', '비리', '에', '대하', '여', '즉각', '적', '인', '수사', '진행', '을', '해야', '합니다', '국내', '최대', '헤지', '펀드', '운용', '사', '자산운용', '영자', '도덕', '해이', '고발', '고객', '돈', '비', '우량', '회사', '투자', '고객', '막대', '손해', '또한', '부사', '사람', '자산', '투자', '회사', '주가조작', '직접', '개입', '회사', '막대', '손해', '뒤', '법윈', '영장', '심사', '날', '잠적', '부사', '국적', '과연', '부사', '단독', '범행', '요', '어제', '이', '회사', '미국', '다단계', '폰', '사기', '휘', '고객', '돈', '억원', '손실', '예상', '기사', '과연', '자산', '웅', '단순', '피해자', '요', '우선', '부실', '다단계', '사기', '것', '인지', '지속', '판매', '도덕', '해이', '당장', '대한민국', '검찰', '머리', '외국인', '임원', '도주', '방관', '은행', '권유', '곳', '투자', '분', '무슨', '잘못', '꼬리', '식', '머리', '외국인', '책임', '전가', '제대로', '수사', '촉구', '게시', '물의', '일부', '내용', '국민', '청원', '요건', '위배', '관리자', '수정'] No\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[단어장 및 DataLoader 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jk/.pyenv/versions/3.10.6/envs/aienv-3.10.6/lib/python3.10/site-packages/torchtext/vocab.py:432: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원 : torch.Size([38909, 100]) \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=\"data/petitions_tokens_w2v\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 TextCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TextCNN 모델링]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 학습 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 평가 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 학습 및 성능 확인]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(38909, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss: 0.08195012721229325 \t Accuracy: 61.539344787597656%\n",
      "Valid Epoch: 1 \t Loss: 0.07944685771294377 \t Accuracy: 63.92463302612305%\n",
      "model saves at 63.92463302612305 accuracy\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.07511634898555478 \t Accuracy: 68.2596206665039%\n",
      "Valid Epoch: 2 \t Loss: 0.07524247734588296 \t Accuracy: 69.0257339477539%\n",
      "model saves at 69.0257339477539 accuracy\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.06579611542956162 \t Accuracy: 73.91154479980469%\n",
      "Valid Epoch: 3 \t Loss: 0.0767463430050103 \t Accuracy: 68.19853210449219%\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1, 3+1):\n",
    " \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "        \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
