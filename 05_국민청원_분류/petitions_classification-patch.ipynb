{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 국민청원 분류하기 패치 Notebook\n",
    "\n",
    "본 Notebook 파일은 기존 Notebook 파일을 실행 가능하도록 수정한 Notebook 입니다.\n",
    "\n",
    "로컬 환경 Windows / Mac os 에서 테스트를 했으며 환경에 따른 모듈 문제로 인해 여러번의 시행착오가 있었습니다.\n",
    "\n",
    "## 주의사항\n",
    "1. 모듈간 의존성 문제로 오류가 발생하는 경우 새로운 가상환경을 만들어서 실행하세요.\n",
    "2. torchtext 모듈 설치 시 환경에 맞는 설치 필요. conda / pip 환경 확인하세요.\n",
    "3. konlpy 모듈은 JAVA 설치를 필요. 아래 konlpy 설치를 참고하세요.\n",
    "\n",
    "## Install Dependencies\n",
    "\n",
    "아래 모듈 설치는 새로운 가상 환경을 만든 후 새롭게 모듈을 설치 한 경우이며, 기존 환경에 설치하는 경우 명령어가 다를 수 있습니다.\n",
    "\n",
    "[모듈 수동 설치]\n",
    "\n",
    "설치 순서 :  pandas > numpy > konlpy > gensim > pytorch (반드시 torchtext 포함하여 설치)\n",
    "\n",
    "만일 CPU 사용 환경이라면 다음 명령으로 pytorch 설치하세요.\n",
    "```bash\n",
    "# install basic modules\n",
    "pip3 install pandas numpy konlpy gensim\n",
    "\n",
    "# install pytorch \n",
    "# if non-conda env\n",
    "pip3 install torch torchvision torchaudio torchtext\n",
    "\n",
    "# if conda env\n",
    "conda install pytorch torchvision torchaudio torchtext cpuonly -c pytorch\n",
    "\n",
    "```\n",
    "\n",
    "GPU를 사용하는 설치는 [Pytorch 사이트}(https://pytorch.org/)를 참고하세요.\n",
    "\n",
    "\n",
    "[모듈 자동 설치]\n",
    "\n",
    "개인별 환경이 다르므로 requirements 설치는 추천하지 않습니다. 설치된 버전 참고만 하시기 바랍니다.\n",
    "\n",
    "```bash\n",
    "# uninstall\n",
    "pip list --format=freeze > installed-requirements.txt\n",
    "pip uninstall -r installed-requirements.txt -y\n",
    "\n",
    "# install for mac os\n",
    "pip install -r requirements-patch.txt\n",
    "\n",
    "# install for windows\n",
    "pip install -r requirements-windows-only-cpu.txt\n",
    "```\n",
    "\n",
    "[konlpy 모듈 설치]\n",
    "```bash \n",
    " pip install konlpy\n",
    "```\n",
    "\n",
    "konlpy는 JAVA dll을 사용하므로 개별 환경에 맞는 JAVA를 설치하시기 바랍니다.\n",
    " - JAVA 1.8.x 버전 이상을 요구합니다.\n",
    " - 환경 별 설치\n",
    "    - mac os : zulu-1.8.x 버전 설치. 테스트 완료.\n",
    "    - windows : oralce 공식 jdk-17.0.12 버전 설치. 테스트 완료. \n",
    "    - Google colab은 [Konlpy 설치 링크](https://riverside13.tistory.com/entry/colab%EC%97%90-konlpy-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0#:~:text=colab%EC%97%90%20konlpy%20%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0%201%201.%20bash%20%EC%85%B8%EB%A1%9C%20%EB%AA%85%EB%A0%B9%EC%96%B4%EB%A5%BC,%EC%84%A4%EC%B9%98%20%28%EC%8B%9C%EA%B0%84%20%EC%A2%80%20%EA%B1%B8%EB%A6%BC%29%204%204.%20%EB%8F%99%EC%9E%91%20%ED%99%95%EC%9D%B8) 참고. 테스트는 진행 하지 못함.\n",
    " - JAVA 설치 후 환경 변수 JAVA_HOME 설정이 필요함.\n",
    " - 단, JAVA_HOME 설정을 하지 않는 경우 소스 코드 내에서 jvm_path 정의 필요.(아래 코드 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "국민 청원 사이트가 없어진 관계로 크롤링 영역은 삭제했습니다.\n",
    "\n",
    "크롤링 코드는 원본 Notebook 에서 확인하세요.\n",
    "\n",
    "크롤링 데이터는 `crawling.zip` 로 제공됩니다.\n",
    "\n",
    "### 준비 사항\n",
    "\n",
    "crawling.zip 압축 해제 : crawling.csv 파일은 ```05_국민청원_분류\\data\\``` 폴더 아래로 이동(Move) 시켜 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 csv 파일 읽기\n",
    "df = pd.read_csv('data/crawling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다. 하지만 투자매력이 없다고도 합니다.이렇게 말하는 이유가 어디 있습니까? 바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다.\\r\\n\\r\\r\\n지금은 투자매력이 없어서 그렇지,..우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과, 외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다. 그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다.\\r\\n\\r\\r\\n정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데,... 그렇지 못한 현실이 안타깝다고 생각합니다.\\r\\r\\n국가가 지원해 돈 들이기가 어려우면,정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다. \\r\\n\\r\\r\\n그래서 저는 정부에 다음과 같이 청원합니다.\\r\\r\\n주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서,...\\r\\n\\r\\r\\n첫째,주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오 \\r\\n\\r\\r\\n둘째,  코스닥 종목은 공매도 제외시켜 주세요.\\r\\n\\r\\r\\n공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다 \\r\\n\\r\\r\\n셋째, 거래시장의 주식거래세를 더 낮춰 주세요 \\r\\n\\r\\r\\n특히 개미(소액)투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다.\\r\\n\\r\\r\\n넷째, 중,장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요.\\r\\n\\r\\r\\n이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']  # 전처리 전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[전처리]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_white_space(text):\n",
    "    text = re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "def remove_special_char(text):\n",
    "    text = re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리 나라 코스피 시총이 미국 애플보다 작다는 설이 돌 정도로 한국의 주식시장은 저평가된 시장이라고 합니다  하지만 투자매력이 없다고도 합니다 이렇게 말하는 이유가 어디 있습니까  바로 투자를 해도 수익을 기대하기 어렵다는 인식이 이미 널리 퍼져 있다는 것입니다      지금은 투자매력이 없어서 그렇지 우리 나라 시중 부동 자금이 어마어마 한 것으로 알려진 것과  외국 투자 자본 또한 실로 어마무지하게 많다는 것도 알고있습니다  그러나 이 투자금이 주식시장으로 원활하게 순환이 안되고 있다는데 있습니다      정부는 유휴자금이 주식 시장으로 들어오게 분위기를 띄어줘야 하는데  그렇지 못한 현실이 안타깝다고 생각합니다    국가가 지원해 돈 들이기가 어려우면 정부에서 정서적인 말이라도 활성화를 위한 관심표명과 정책적으로 지원만 해도 시장분위기는 많이 좋아질 것이라 확신합니다       그래서 저는 정부에 다음과 같이 청원합니다    주식시장에 더 큰 충격 오기 전에 정부가 예방 조치를 할 수 있는데까지 노력해 주시기를 당부 드리면서      첫째 주식시장 활성화와 부양에 대한 정부의 의지를 표명해 주십시오      둘째   코스닥 종목은 공매도 제외시켜 주세요      공매도 제도를 아예 없애버리면 좋겠지만 제도를 살린다면 적용 시장에서 코스닥 종목은 제외 해 주어야 체력이 약한 코스닥 시장을 안정시킬 수 있다고 봅니다      셋째  거래시장의 주식거래세를 더 낮춰 주세요      특히 개미 소액 투자에 동일한 요율로 부과하는 것은 너무나 불공정 하다고 봅니다      넷째  중 장기 보유자에 대한 우대 차원에서 보유기간을 설정하여 주세요      이는 장기 보유자에 대한 혜택을 주어 초단타매매 등 시장 질서를 교란하는 투자자와 분리하는 제도를 도입해 시장 안정화에 기여해 주시길 간곡히 부탁드리면서 청원합니다 '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]['content']  # 전처리 후"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 토크나이징 및 변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[토크나이징]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME not found.\n",
      "Platform name : Windows\n",
      "title_token completed.\n",
      "content_token completed.\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import platform\n",
    "\n",
    "# konlpy 에서 JAVA 필요함.\n",
    "# JVM 1.8 버전 이상\n",
    "try:\n",
    "    # JAVA_HOME 설정이 된 경우\n",
    "    # JAVA_HOME 설정이 되더라도 dll을 찾지 못해 오류가 발생할 수 있음.\n",
    "    okt = Okt()\n",
    "except:\n",
    "    # JAVA_HOME 설정이 없는 경우 직접 설정\n",
    "    print('JAVA_HOME not found.')\n",
    "    \n",
    "    # check platform\n",
    "    platform_name = platform.system()\n",
    "    print(f'Platform name : {platform_name}')\n",
    "\n",
    "    if platform_name=='Darwin': # for mac os\n",
    "        # JVM_PATH konlpy 가 요구하는 dylib 파일 경로로 셋팅.\n",
    "        # mac os의 경우 JDK 설치 후 설치된 폴더명을 1.8.0을 포함하도록 변경 필요함. ex) zulu-1.8.jdk -> zulu-1.8.0.jdk\n",
    "        # konlpy 가 요구하는 libjli.dylib 파일 경로로 셋팅.\n",
    "        JVM_PATH = '/Library/Java/JavaVirtualMachines/zulu-1.8.0.jdk/Contents/Home/jre/lib/jli/libjli.dylib'\n",
    "    else:\n",
    "        # konlpy 가 요구하는 jvm.dll 파일 경로로 셋팅.\n",
    "        JVM_PATH = 'C:\\\\Library\\\\Java\\\\jdk-17.0.12\\\\bin\\\\server\\\\jvm.dll'\n",
    "    okt = Okt(jvmpath=JVM_PATH)\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "print('title_token completed.')\n",
    "df['content_token'] = df.content.apply(okt.nouns)\n",
    "print('content_token completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[파생변수 생성]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category         object\n",
      "content          object\n",
      "count             int64\n",
      "end              object\n",
      "start            object\n",
      "title            object\n",
      "title_token      object\n",
      "content_token    object\n",
      "token_final      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_drop = df[['token_final', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_final</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         token_final label\n",
       "0  [서울, 지방, 병무청, 탈의실, 에, 설치, 된, 에, 대한, 진상, 규명, 을,...    No\n",
       "1  [주식시장, 활성화, 및, 소액, 개미, 투자자, 보호, 우리, 나라, 코스피, 총...    No\n",
       "2  [교정, 기관, 의, 민낮, 일로, 국민, 청원, 신청, 저, 구치소, 교도관, 이...    No\n",
       "3  [미세먼지, 저, 감, 대책, 미세먼지, 심각, 성은, 이제, 적극, 대안, 요구,...    No\n",
       "4  [악질, 세, 입자, 방지, 를, 위, 한, 세, 입자, 보호, 법, 을, 재정, ...   Yes"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 엑셀로 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_drop.to_csv('data/df_drop.csv', index = False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 단어 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[단어 임베딩]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=42642, vector_size=100, alpha=0.025>\n",
      "[('음주', 0.8596104383468628), ('뺑소니', 0.839146077632904), ('무면허', 0.8311192393302917), ('살인죄', 0.7677296996116638), ('살인자', 0.7575804591178894), ('윤창', 0.7524190545082092), ('전과자', 0.742548942565918), ('형량', 0.7399409413337708), ('촉법소년', 0.7383947372436523), ('엄하', 0.7378968000411987)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'], \n",
    "                           sg = 1, # skip-gram\n",
    "                           vector_size = 100, \n",
    "                           window = 2, \n",
    "                           min_count = 1, \n",
    "                           workers = 4\n",
    "                           )\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "model_result = embedding_model.wv.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[임베딩 모델 저장 및 로드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('음주', 0.8596104383468628), ('뺑소니', 0.839146077632904), ('무면허', 0.8311192393302917), ('살인죄', 0.7677296996116638), ('살인자', 0.7575804591178894), ('윤창', 0.7524190545082092), ('전과자', 0.742548942565918), ('형량', 0.7399409413337708), ('촉법소년', 0.7383947372436523), ('엄하', 0.7378968000411987)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "embedding_model.wv.save_word2vec_format('data/petitions_tokens_w2v.pkl') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format('data/petitions_tokens_w2v.pkl') # 모델 로드\n",
    "\n",
    "model_result = loaded_model.most_similar(\"음주운전\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 실험 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터셋 분할 및 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[~df_drop.index.isin(tr.index)]\n",
    "\n",
    "tr.to_csv('data/train.csv', index=False, encoding='utf-8-sig')\n",
    "val.to_csv('data/validation.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Field클래스 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('[\\[\\]\\']', '', str(text))\n",
    "    text = text.split(', ')\n",
    "    return text\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['유부', '남', '유부녀', '의', '미혼', '빙자', '에', '대한', '처벌', '이나', '대안', '이', '필요합니다', '사람', '만남', '개인', '사항', '생각', '영화', '소설', '속', '일이', '생각', '작년', '교재', '남자', '첫', '만남', '나이', '결혼', '생각', '미혼', '서로', '감정', '쌍둥이', '자연', '임신', '사실', '때', '바로', '이별', '말', '뒤', '말', '못', '유전병', '그', '아픔', '애', '결혼', '생각', '다음', '만날', '때', '타지', '파견', '근무', '혼인신고', '것', '부모님', '결혼', '반대', '며', '집안', '점', '여자', '안보', '저', '결혼', '반대', '설득', '시간', '또', '시간', '대뜸', '사실', '결혼', '처음', '서로', '결혼', '자주', '양가', '부모님', '혼반', '서로', '일', '터치', '연락', '살기', '별거', '및', '왕래', '즉', '서류', '유부', '남', '애', '별거', '이상', '요', '충격', '쌍둥이', '아빠', '이혼', '생각', '물음', '이혼', '답', '애도', '둘', '사이', '연락', '저', '사이', '전', '불륜', '녀', '혼외자', '사람', '매일', '울', '충격', '생명', '둘', '눈총', '게', '감수', '생각', '오늘', '사실', '딸', '부모님', '부인', '집안', '행사', '부모님', '참여', '왕래', '이혼', '딸', '노력', '지금', '시간', '온', '상투', '말로', '저', '제', '쌍둥이', '비수', '꽃았습니', '유부', '남', '애도', '저희', '가족', '친척', '일터', '사람', '지인', '지금', '시간', '지방법원', '무료', '변호사', '처지', '답', '법률', '사무소', '처벌', '손해배상', '청구', '상', '녀', '손해배상', '소송', '제', '오늘', '모든', '걸', '알', '낙태', '불법', '혼빙죄', '성적', '자기결정권', '침해', '손해배상', '청구', '제', '정신', '육체', '고통', '배상', '액', '돈', '건', '죄', '쌍둥이', '생각', '한탄', '죽음', '선택', '현실', '이', '상황', '대해', '아무', '사람', '하나', '것', '저', '사이', '제', '불륜', '녀', '미혼모', '대해', '책임', '조치', '수', '것', '마음', '청원', '저', '더', '고난', '분', '금전', '피해', '사기죄', '유부', '남', '만난', '제', '잘못', '스스로', '질책', '태교', '신경', '때', '제대로', '못', '눈물', '밤', '워', '저', '피해자', '발생', '법', '제도', '틀', '마련', '두서', '글', '제', '여자', '유부', '남', '대한', '것', '판단', '게', '유부녀', '대한', '남자', '피해', '거', '남여', '성별', '기혼', '임', '속', '상대', '정신', '육체', '피해', '행위', '대해', '선', '대안', '생각'] No\n",
      "Validation: ['악질', '세', '입자', '방지', '를', '위', '한', '세', '입자', '보호', '법', '을', '재정', '해주세요', '저', '우선', '아이', '셋', '부모', '식구', '편이', '아이', '집', '나름', '꿈', '가지', '좀더', '집', '분양', '아이', '학교', '문제', '분양', '집', '바로', '상황', '우선', '월세', '보증금', '백', '월', '보증금', '가격', '이유', '입자', '입자', '이후', '관리', '비', '한번', '걸', '알', '나름', '유주', '입자', '생활', '연락', '집주인', '관리', '비', '일일이', '체크', '웃기', '생각', '체납', '유주', '입자', '주시', '등', '한번', '주의', '알림', '관리소', '원망', '관리', '비', '보증금', '월세', '보증금', '멸후', '개월', '손해', '육박', '나름', '배려', '저희', '일주일', '뒤', '달뒤', '말', '전혀', '노력', '입자', '달', '달이', '지옥', '저희', '대출', '이자', '매', '마이너스', '통장', '이제', '더', '이상', '한계', '입자', '농락', '기분', '막상', '단전', '입자', '관리', '사무소', '입자', '보호', '법', '이야기', '이', '말', '사람', '난방', '수도', '전기', '저희', '빚', '요', '왜', '국가', '입자', '보호', '법', '는걸', '국가', '돈', '보호', '유주', '돈', '세입', '자만', '보호', '유주', '악한', '유주', '단전', '집주인', '누가', '부동산', '입자', '보호', '법', '수정', '금지', '입자', '보호', '법', '보증금', '상태', '적용', '입자', '보호', '법도', '예외', '법안', '명도', '소송도', '보증금', '경우', '제외', '보증금', '입자', '농간', '소유', '주의', '빚', '때', '소송', '진행', '법안', '시기', '정말', '법', '악용', '악질', '입자', '존재', '정말', '유주', '입장', '악질', '입자', '때문', '가슴앓이', '눈물', '경우', '사실', '꼭', '인지', '내', '집', '내', '살', '보지', '못', '새집', '생판', '피', '타인', '점거', '어이', '제때', '가지', '못', '이', '뭐', '상황', '한탄'] Yes\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path = 'data/',\n",
    "    train = 'train.csv',\n",
    "    validation = 'validation.csv',\n",
    "    format = 'csv',\n",
    "    fields = [('text', TEXT), ('label', LABEL)],\n",
    "    skip_header = True\n",
    ")\n",
    "\n",
    "print(\"Train:\", train[0].text,  train[0].label)\n",
    "print(\"Validation:\", validation[0].text, validation[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[단어장 및 DataLoader 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeong\\anaconda3\\envs\\petitions-cpu-env\\lib\\site-packages\\torchtext\\vocab.py:432: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 벡터의 개수와 차원 : torch.Size([39118, 100]) \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=\"data/petitions_tokens_w2v.pkl\")\n",
    "\n",
    "TEXT.build_vocab(train, vectors = vectors, min_freq = 1, max_size = None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets = (train, validation),\n",
    "    batch_size = 8,\n",
    "    device = device,\n",
    "    sort = False\n",
    ")\n",
    "\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 TextCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TextCNN 모델링]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn   \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "class TextCNN(nn.Module): \n",
    "    \n",
    "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
    "        \n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
    "        self.embed.weight.data.copy_(vocab_built.vectors)      \n",
    "    \n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, emb_dim)) for w in kernel_wins])\n",
    "        self.relu = nn.ReLU()                \n",
    "        self.dropout = nn.Dropout(0.4)         \n",
    "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)     \n",
    "        \n",
    "    def forward(self, x):  \n",
    "      \n",
    "        emb_x = self.embed(x)           \n",
    "        emb_x = emb_x.unsqueeze(1)  \n",
    "\n",
    "        con_x = [self.relu(conv(emb_x)) for conv in self.convs]       \n",
    "\n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in con_x]    \n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1) \n",
    "        fc_x = fc_x.squeeze(-1)       \n",
    "        fc_x = self.dropout(fc_x)         \n",
    "\n",
    "        logit = self.fc(fc_x)     \n",
    "        \n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 학습 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_itr, optimizer):\n",
    "    \n",
    "    model.train()                               \n",
    "    corrects, train_loss = 0.0,0        \n",
    "    \n",
    "    for batch in train_itr:\n",
    "        \n",
    "        text, target = batch.text, batch.label      \n",
    "        text = torch.transpose(text, 0, 1)          \n",
    "        target.data.sub_(1)                                 \n",
    "        text, target = text.to(device), target.to(device)  \n",
    "\n",
    "        optimizer.zero_grad()                           \n",
    "        logit = model(text)                         \n",
    "    \n",
    "        loss = F.cross_entropy(logit, target)   \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "        result = torch.max(logit,1)[1] \n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    train_loss /= len(train_itr.dataset)\n",
    "    accuracy = 100.0 * corrects / len(train_itr.dataset)\n",
    "\n",
    "    return train_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 평가 함수 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, device, itr):\n",
    "    \n",
    "    model.eval()\n",
    "    corrects, test_loss = 0.0, 0\n",
    "\n",
    "    for batch in itr:\n",
    "        \n",
    "        text = batch.text\n",
    "        target = batch.label\n",
    "        text = torch.transpose(text, 0, 1)\n",
    "        target.data.sub_(1)\n",
    "        text, target = text.to(device), target.to(device)\n",
    "        \n",
    "        logit = model(text)\n",
    "        loss = F.cross_entropy(logit, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        result = torch.max(logit,1)[1]\n",
    "        corrects += (result.view(target.size()).data == target.data).sum()\n",
    "\n",
    "    test_loss /= len(itr.dataset) \n",
    "    accuracy = 100.0 * corrects / len(itr.dataset)\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[모델 학습 및 성능 확인]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (embed): Embedding(39118, 100)\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 10, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 10, kernel_size=(4, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 10, kernel_size=(5, 100), stride=(1, 1))\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=30, out_features=2, bias=True)\n",
      ")\n",
      "Train Epoch: 1 \t Loss: 0.08421617247194206 \t Accuracy: 58.63296890258789%\n",
      "Valid Epoch: 1 \t Loss: 0.08223568242700662 \t Accuracy: 61.25918960571289%\n",
      "model saves at 61.25918960571289 accuracy\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 2 \t Loss: 0.07749072197249127 \t Accuracy: 66.24928283691406%\n",
      "Valid Epoch: 2 \t Loss: 0.07875609837527223 \t Accuracy: 65.3492660522461%\n",
      "model saves at 65.3492660522461 accuracy\n",
      "-----------------------------------------------------------------------------\n",
      "Train Epoch: 3 \t Loss: 0.06003378599385706 \t Accuracy: 77.93222045898438%\n",
      "Valid Epoch: 3 \t Loss: 0.08393647925079088 \t Accuracy: 62.82168960571289%\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = TextCNN(vocab, 100, 10, [3, 4, 5], 2).to(device)\n",
    "print(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "best_test_acc = -1\n",
    "\n",
    "for epoch in range(1, 3+1):\n",
    " \n",
    "    tr_loss, tr_acc = train(model, device, train_iter, optimizer) \n",
    "    print('Train Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, tr_loss, tr_acc))\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, device, validation_iter)\n",
    "    print('Valid Epoch: {} \\t Loss: {} \\t Accuracy: {}%'.format(epoch, val_loss, val_acc))\n",
    "        \n",
    "    if val_acc > best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        \n",
    "        print(\"model saves at {} accuracy\".format(best_test_acc))\n",
    "        torch.save(model.state_dict(), \"TextCNN_Best_Validation\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
